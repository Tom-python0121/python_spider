# douban_spider.py
import requests
from bs4 import BeautifulSoup  # ç½‘é¡µè§£æå™¨
import pandas as pd
import time                    # æ§åˆ¶è®¿é—®é—´éš”
from feishu_uploader import get_token, upload_to_feishu

# ==============================
# 1ï¸âƒ£ çˆ¬å–è±†ç“£ Top250 å‰ 100 æ¡
# ==============================
def get_douban_top100():
    """
    ä»è±†ç“£ Top250 é¡µé¢æŠ“å–å‰ 100 æ¡ç”µå½±ä¿¡æ¯ã€‚
    ä½¿ç”¨ requests + BeautifulSoupã€‚
    """

    # è®¾ç½®è¯·æ±‚å¤´ï¼Œæ¨¡æ‹Ÿæµè§ˆå™¨è®¿é—®ï¼Œé˜²æ­¢è¢«å°
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                      "AppleWebKit/537.36 (KHTML, like Gecko) "
                      "Chrome/120.0.0.0 Safari/537.36",
        "Referer": "https://movie.douban.com/",
        "Accept-Language": "zh-CN,zh;q=0.9",
    }

    movies = []  # ç”¨äºå­˜æ”¾æ‰€æœ‰ç”µå½±å­—å…¸çš„åˆ—è¡¨

    # è¿™é‡Œé€šè¿‡åˆ†é¡µå‚æ•° startï¼Œæ¯é¡µ 25 æ¡
    for start in range(0, 100, 25):
        url = f"https://movie.douban.com/top250?start={start}"
        res = requests.get(url, headers=headers, timeout=10)
        res.encoding = "utf-8"  # æŒ‡å®šä¸­æ–‡ç¼–ç 
        soup = BeautifulSoup(res.text, "html.parser")

        # æŸ¥æ‰¾æ‰€æœ‰ç”µå½±æ¡ç›® div
        for item in soup.select("div.item"):
            title = item.select_one("span.title").get_text(strip=True)
            rating = item.select_one("span.rating_num").get_text(strip=True)
            link = item.select_one("a")["href"]
            info = item.select_one("div.bd p").get_text(strip=True)

            # å°†ä¸€æ¡ç”µå½±ä¿¡æ¯å­˜å…¥å­—å…¸
            movies.append({
                "ç”µå½±åç§°": title,
                "è¯„åˆ†": rating,
                "é“¾æ¥": link,
                "è¯¦æƒ…": info
            })

        print(f"ğŸ“„ å·²æŠ“å– {len(movies)} æ¡...")
        time.sleep(1)  # æ¯é¡µæš‚åœ 1 ç§’ï¼Œé˜²æ­¢å° IP

    print(f"âœ… å…±æŠ“å–åˆ° {len(movies)} æ¡ç”µå½±æ•°æ®")

    # è½¬ä¸º DataFrameï¼Œæ–¹ä¾¿åç»­ä¿å­˜/ä¸Šä¼ 
    return pd.DataFrame(movies)


# ==============================
# 2ï¸âƒ£ ä¸»å‡½æ•°å…¥å£
# ==============================
if __name__ == "__main__":
    print("ğŸ¬ æ­£åœ¨çˆ¬å–è±†ç“£ Top100...")

    # è°ƒç”¨çˆ¬å–å‡½æ•°
    df = get_douban_top100()

    # ä¿å­˜æœ¬åœ°å¤‡ä»½
    df.to_csv("douban_top100.csv", index=False, encoding="utf-8-sig")
    print("âœ… å·²ä¿å­˜åˆ° douban_top100.csv")

    # ä¸Šä¼ åˆ°é£ä¹¦
    print("ğŸ” æ­£åœ¨è¿æ¥é£ä¹¦...")
    token = get_token()
    upload_to_feishu(df, token)
    print("ğŸš€ å…¨éƒ¨ä¸Šä¼ å®Œæ¯•ï¼")
